{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet34\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset, read_pred_csv\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict, defaultdict\n",
    "import copy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data path and load cfg\n",
    "\n",
    "By setting the `L5KIT_DATA_FOLDER` variable, we can point the script to the folder where the data lies.\n",
    "\n",
    "Then, we load our config file with relative paths and other configurations (rasteriser, training params...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# training cfg\n",
    "validation_cfg = {\n",
    "    \n",
    "    'format_version': 4,\n",
    "    \n",
    "     ## Model options\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet34',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "    },\n",
    "\n",
    "    ## Input raster parameters\n",
    "    'raster_params': {\n",
    "        \n",
    "        'raster_size': [224, 224], # raster's spatial resolution [meters per pixel]: the size in the real world one pixel corresponds to.\n",
    "        'pixel_size': [0.5, 0.5], # From 0 to 1 per axis, [0.5,0.5] would show the ego centered in the image.\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': \"py_semantic\",\n",
    "        \n",
    "        # the keys are relative to the dataset environment variable\n",
    "        'satellite_map_key': \"aerial_map/aerial_map.png\",\n",
    "        'semantic_map_key': \"semantic_map/semantic_map.pb\",\n",
    "        'dataset_meta_key': \"meta.json\",\n",
    "\n",
    "        # e.g. 0.0 include every obstacle, 0.5 show those obstacles with >0.5 probability of being\n",
    "        # one of the classes we care about (cars, bikes, peds, etc.), >=1.0 filter all other agents.\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    ## Data loader options\n",
    "    'valid_data_loader': {\n",
    "        'key': \"scenes/validate_chopped_100/validate.zarr\",\n",
    "        'batch_size': 1,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "    },\n",
    "\n",
    "    ## Valid params\n",
    "    'valid_params': {\n",
    "        'checkpoint_every_n_steps': 5000,\n",
    "        'max_num_steps': 10 if DEBUG else 1000\n",
    "    }\n",
    "}\n",
    "\n",
    "common_cfg = {\n",
    "    'seed': 500,\n",
    "    'output_dir': './subs/',\n",
    "    'epoch': 2,\n",
    "    'train_step': 5 if DEBUG else 500,\n",
    "    'valid_step': 5 if DEBUG else 50,\n",
    "    'train_max': 12,\n",
    "    'learning_rate': 1e-3\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = common_cfg['output_dir']\n",
    "INPUT_ROOT = Path('/home/knikaido/work/Lyft/data/')\n",
    "DATA_DIR = INPUT_ROOT / 'lyft-motion-prediction-autonomous-vehicles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path1 = f\"{OUTPUT_DIR}sub_ansamble.csv\"\n",
    "pred_path2 = f\"{OUTPUT_DIR}sub_ansamble_22_28.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pathes = [pred_path1, pred_path2]\n",
    "outputs = []\n",
    "for path in pred_pathes:\n",
    "    output = pd.read_csv(path)\n",
    "    output.sort_values(['timestamp', 'track_id'], inplace=True)\n",
    "    output.reset_index(inplace=True, drop=True)\n",
    "    outputs.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_predicts = []\n",
    "t_confs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71122/71122 [03:03<00:00, 387.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(71122)):\n",
    "    predicts = []\n",
    "    confs = []\n",
    "    confs.append(outputs[0].loc[i, 'conf_0'])\n",
    "    confs.append(outputs[0].loc[i, 'conf_1'])\n",
    "    confs.append(outputs[0].loc[i, 'conf_2'])\n",
    "    predicts.append(outputs[0].loc[i, 'coord_x00':'coord_y049'].values)\n",
    "    predicts.append(outputs[0].loc[i, 'coord_x10':'coord_y149'].values)\n",
    "    predicts.append(outputs[0].loc[i, 'coord_x20':'coord_y249'].values)\n",
    "    confs.append(outputs[1].loc[i, 'conf_0'])\n",
    "    confs.append(outputs[1].loc[i, 'conf_1'])\n",
    "    confs.append(outputs[1].loc[i, 'conf_2'])\n",
    "    predicts.append(outputs[1].loc[i, 'coord_x00':'coord_y049'].values)\n",
    "    predicts.append(outputs[1].loc[i, 'coord_x10':'coord_y149'].values)\n",
    "    predicts.append(outputs[1].loc[i, 'coord_x20':'coord_y249'].values)\n",
    "\n",
    "    t_predicts.append(predicts)\n",
    "    t_confs.append(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(coord1, coord2):\n",
    "    coord1 = coord1.reshape(-1, 2)\n",
    "    coord2= coord2.reshape(-1, 2)\n",
    "    distance = 0\n",
    "    cos = 0\n",
    "    for i in range(len(coord1)):\n",
    "        cos += cos_sim(coord2[i], coord1[i])\n",
    "        distance += pow(coord2[i, 0] - coord1[i, 0], 2) + pow(coord2[i, 1] - coord1[i, 1], 2)\n",
    "        \n",
    "    return cos / len(coord1), np.sqrt(distance)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_preds(tmp_predicts, tmp_conf, thre=15):\n",
    "    \n",
    "    \n",
    "    predicts = copy.deepcopy(tmp_predicts)\n",
    "    confs = copy.deepcopy(tmp_conf)\n",
    "    \n",
    "    ans_preds = []\n",
    "    ans_confs = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        ind = np.argmax(confs)\n",
    "        pre1 = predicts[ind]\n",
    "        ans_preds.append(pre1)\n",
    "        ans_confs.append(confs[ind])\n",
    "        predicts.pop(ind)\n",
    "        confs.pop(ind)\n",
    "\n",
    "        predicts_ = []\n",
    "        confs_ = []\n",
    "        for i in range(len(predicts)):\n",
    "            angle, dist = calc_distance(pre1, np.array(predicts[i]))\n",
    "            if(dist > thre):\n",
    "                predicts_.append(predicts[i])\n",
    "                confs_.append(confs[i])\n",
    "                \n",
    "        if(len(confs_)<3):\n",
    "            return tmp_predicts[0:3], tmp_conf[0:3] / np.sum(tmp_conf[0:3])\n",
    "            \n",
    "        predicts = predicts_\n",
    "        confs = confs_\n",
    "        \n",
    "    ans_confs = ans_confs / np.sum(ans_confs)\n",
    "    return ans_preds, ans_confs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(t_confs)):\n",
    "    for j in range(3):\n",
    "#         t_confs[i][j] = t_confs[i][j] * 2  \n",
    "        t_confs[i][j] = t_confs[i][j] * 10 * (26.2 / 21.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_output = pd.read_csv(str(OUTPUT_DIR)+'sub1010.csv')\n",
    "ans_output.sort_values(['timestamp', 'track_id'], inplace=True)\n",
    "ans_output.reset_index(inplace=True, drop=True)\n",
    "ans_conf = ans_output.loc[:, 'conf_0':'conf_2']\n",
    "ans_coord= ans_output.loc[:, 'coord_x00':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 42794/71122 [03:34<02:28, 190.20it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "100%|██████████| 71122/71122 [05:56<00:00, 199.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(range(len(ans_output))):\n",
    "    prepre, concon = decide_preds(t_predicts[j], t_confs[j])\n",
    "\n",
    "    ans_conf.iloc[j] = concon\n",
    "    ans_coord.iloc[j] = np.array(prepre).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_output.loc[:, 'conf_0':'conf_2'] = ans_conf\n",
    "ans_output.loc[:, 'coord_x00':] = ans_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_output_ = pd.read_csv(str(OUTPUT_DIR)+'sub1010.csv')\n",
    "ans_output_.sort_values(['timestamp', 'track_id'], inplace=True)\n",
    "ans_output.index = ans_output_.index\n",
    "ans_output.sort_index(inplace=True)\n",
    "ans_output.to_csv(str(OUTPUT_DIR)+'sub_ansamble_ble.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
